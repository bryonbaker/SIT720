{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a6c237-a737-4a91-bc0d-ade5b2e5f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "import pandas as pd # dataframe manipulation\n",
    "import numpy as np # linear algebra\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Configure ssl for unverified content so we can load a dataset from an unknown source (github).\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b350ff1-2082-4328-975a-30224edab440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load datasets from local or remote resource:\n",
      "==================================================\n",
      "Training data is local\n",
      "Test data is local\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#train_url = 'https://raw.githubusercontent.com/bryonbaker/datasets/main/SIT720/Ass3/ac_train_data.csv'\n",
    "train_url = 'https://raw.githubusercontent.com/bryonbaker/datasets/main/SIT720/Ass3/debug_ac_train_data.csv'\n",
    "test_url = 'https://raw.githubusercontent.com/bryonbaker/datasets/main/SIT720/Ass3/ac_test_data.csv'\n",
    "train_path = '/opt/app-root/src/datasets/SIT720/Ass3/ac_train_data.csv'\n",
    "test_path = '/opt/app-root/src/datasets/SIT720/Ass3/ac_test_data.csv'\n",
    "\n",
    "#\n",
    "# Work out if the datasets are local. If not use a remote url. Preference is local.\n",
    "#\n",
    "print(\"Load datasets from local or remote resource:\")\n",
    "print(\"=\"*50)\n",
    "if os.path.isfile(train_path):\n",
    "    print(\"Training data is local\")\n",
    "    training_data = train_path\n",
    "else:\n",
    "    print(\"Training data is remote. Downloading file from: {}\".format(train_url))\n",
    "    training_data = train_url\n",
    "\n",
    "if os.path.isfile(test_path):\n",
    "    print(\"Test data is local\")\n",
    "    test_data = test_path\n",
    "else:\n",
    "    print(\"Test data is remote. Downloading file from: {}\".format(test_url))\n",
    "    test_data = test_url\n",
    "print()\n",
    "\n",
    "# Load the datasets from either local or remote.\n",
    "train_df = pd.read_csv(training_data)\n",
    "test_df = pd.read_csv(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e631d798-4101-4b17-abea-58d295a6a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns not used in the assignment\n",
    "\n",
    "# Drop the sequence number (column 0) from the test dataset. Column 0 is unlabeled so use the index number.\n",
    "train_df = train_df.drop(train_df.columns[[0]],axis=1)\n",
    "test_df = test_df.drop(test_df.columns[[0]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f97a15-cc3c-44c2-b4da-f563dcbe7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encode the days of week.\n",
    "\n",
    "oldCol = \"dayofweek\"\n",
    "newCol = \"dayofweeknum\"\n",
    "dayMap = {'Sun' : 0, 'Mon': 1, \"Tue\" : 2, \"Wed\" : 3, \"Thu\" : 4, \"Fri\" : 5, \"Sat\" : 6 }    # How to map the values\n",
    "\n",
    "train_df[newCol] = train_df[oldCol].map(dayMap)    # Adds a new column with proper boolean values\n",
    "train_df = train_df.drop([oldCol], axis=1)    # Drop the old column before renaming the new column to the name just dropped\n",
    "train_df = train_df.rename(columns={newCol : oldCol})\n",
    "      \n",
    "# Ordinal encode the dayof week in the test dataset.\n",
    "test_df[newCol] = test_df[oldCol].map(dayMap)    # Adds a new column with proper boolean values\n",
    "test_df = test_df.drop([oldCol], axis=1)    # Drop the old column before renaming the new column to the name just dropped\n",
    "test_df = test_df.rename(columns={newCol : oldCol})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991ab3af-cc3b-4e99-8d5d-6e2b84626940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset\n",
      "    load  hourofday    dif  absdif    max       var   entropy  nonlinear  \\\n",
      "0  2.245          0  0.987   0.987  6.215  3.074549  0.678886   0.052903   \n",
      "1  2.259          0  0.014   0.014  6.215  3.172867  0.667450   0.054829   \n",
      "2  2.269          0  0.010   0.010  6.215  3.270112  0.647777   0.056991   \n",
      "3  2.268          0 -0.001   0.001  6.215  3.303763  0.629227   0.057606   \n",
      "4  2.270          0  0.002   0.002  6.215  3.302744  0.621295   0.082640   \n",
      "\n",
      "      hurst  dayofweek  \n",
      "0  0.994071          0  \n",
      "1  0.994154          0  \n",
      "2  0.994220          0  \n",
      "3  0.994150          0  \n",
      "4  0.994041          0  \n",
      "\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: ac, dtype: int64\n",
      "\n",
      "Testing Dataset\n",
      "    load  hourofday    dif  absdif  max  var  entropy  nonlinear  hurst  \\\n",
      "0  1.869          0  0.000   0.000  0.0  0.0      0.0        0.0    0.0   \n",
      "1  1.673          0 -0.196   0.196  0.0  0.0      0.0        0.0    0.0   \n",
      "2  1.660          0 -0.013   0.013  0.0  0.0      0.0        0.0    0.0   \n",
      "3  1.772          0  0.112   0.112  0.0  0.0      0.0        0.0    0.0   \n",
      "4  1.679          0 -0.093   0.093  0.0  0.0      0.0        0.0    0.0   \n",
      "\n",
      "   dayofweek  \n",
      "0          1  \n",
      "1          1  \n",
      "2          1  \n",
      "3          1  \n",
      "4          1  \n",
      "\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: ac, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split out the X and y from the datasets\n",
    "train_X = train_df.drop(['ac'], axis=1)\n",
    "train_y = train_df[\"ac\"]\n",
    "test_X = test_df.drop(['ac'], axis=1)\n",
    "test_y = test_df['ac']\n",
    "\n",
    "print(\"Training Dataset\")\n",
    "print(f\"{train_X.head()}\\n\")\n",
    "print(f\"{train_y.head()}\\n\")\n",
    "\n",
    "print(\"Testing Dataset\")\n",
    "print(f\"{test_X.head()}\\n\")\n",
    "print(f\"{test_y.head()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "77f75d40-16a7-494d-a991-8d989b59ddff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of splits: 10\n",
      "Split: 1: Accuracy: 0.9781956075209354 0.97556142668428 0.9787939032471835 0.9771749917300694\n",
      "[[19422   444]\n",
      " [  384 17724]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     19866\n",
      "           1       0.98      0.98      0.98     18108\n",
      "\n",
      "    accuracy                           0.98     37974\n",
      "   macro avg       0.98      0.98      0.98     37974\n",
      "weighted avg       0.98      0.98      0.98     37974\n",
      "\n",
      "Split: 2: Accuracy: 0.9837257070627271 0.9847786420820128 0.9855358000961076 0.9851570756076472\n",
      "[[16847   317]\n",
      " [  301 20509]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.98      0.98     17164\n",
      "           1       0.98      0.99      0.99     20810\n",
      "\n",
      "    accuracy                           0.98     37974\n",
      "   macro avg       0.98      0.98      0.98     37974\n",
      "weighted avg       0.98      0.98      0.98     37974\n",
      "\n",
      "Split: 3: Accuracy: 0.9905461631642702 0.9911807428927163 0.9902047162477325 0.9906924891758057\n",
      "[[18509   170]\n",
      " [  189 19106]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     18679\n",
      "           1       0.99      0.99      0.99     19295\n",
      "\n",
      "    accuracy                           0.99     37974\n",
      "   macro avg       0.99      0.99      0.99     37974\n",
      "weighted avg       0.99      0.99      0.99     37974\n",
      "\n",
      "Split: 4: Accuracy: 0.9873861062832464 0.9821833098634666 0.9884165126309303 0.985290053127783\n",
      "[[21453   291]\n",
      " [  188 16042]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     21744\n",
      "           1       0.98      0.99      0.99     16230\n",
      "\n",
      "    accuracy                           0.99     37974\n",
      "   macro avg       0.99      0.99      0.99     37974\n",
      "weighted avg       0.99      0.99      0.99     37974\n",
      "\n",
      "Split: 5: Accuracy: 0.9848843945857693 0.9609774944460543 0.9831999209408044 0.9719617037905431\n",
      "[[27451   404]\n",
      " [  170  9949]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      0.99      0.99     27855\n",
      "           1       0.96      0.98      0.97     10119\n",
      "\n",
      "    accuracy                           0.98     37974\n",
      "   macro avg       0.98      0.98      0.98     37974\n",
      "weighted avg       0.99      0.98      0.98     37974\n",
      "\n",
      "Split: 6: Accuracy: 0.9906251645862959 0.8552774755168662 0.9458483754512635 0.8982857142857144\n",
      "[[36046   266]\n",
      " [   90  1572]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      1.00     36312\n",
      "           1       0.86      0.95      0.90      1662\n",
      "\n",
      "    accuracy                           0.99     37974\n",
      "   macro avg       0.93      0.97      0.95     37974\n",
      "weighted avg       0.99      0.99      0.99     37974\n",
      "\n",
      "Split: 7: Accuracy: 0.9771422552272607 0.0 1.0 0.0\n",
      "[[37106   868]\n",
      " [    0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.98      0.99     37974\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.98     37974\n",
      "   macro avg       0.50      0.49      0.49     37974\n",
      "weighted avg       1.00      0.98      0.99     37974\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 8: Accuracy: 0.9953389161004899 0.0 1.0 0.0\n",
      "[[37797   177]\n",
      " [    0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37974\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00     37974\n",
      "   macro avg       0.50      0.50      0.50     37974\n",
      "weighted avg       1.00      1.00      1.00     37974\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 9: Accuracy: 0.9888081318797072 0.0 1.0 0.0\n",
      "[[37549   425]\n",
      " [    0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.99      0.99     37974\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           0.99     37974\n",
      "   macro avg       0.50      0.49      0.50     37974\n",
      "weighted avg       1.00      0.99      0.99     37974\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 10: Accuracy: 0.995496918944541 0.0 1.0 0.0\n",
      "[[37803   171]\n",
      " [    0     0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     37974\n",
      "           1       0.00      0.00      0.00         0\n",
      "\n",
      "    accuracy                           1.00     37974\n",
      "   macro avg       0.50      0.50      0.50     37974\n",
      "weighted avg       1.00      1.00      1.00     37974\n",
      "\n",
      "Average Accuracy: 0.9872149365355243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/opt/app-root/lib64/python3.8/site-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "# Use TimeSeriesSplit. We will make the time series the equivalent of 4 hour periods (even though the back of the data is not continuous)\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "\n",
    "# Define the split details.\\\n",
    "n_splits = 10\n",
    "test_size = int(train_X.shape[0]/11)\n",
    "print(\"Number of splits: {}\".format(n_splits))\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits, test_size=test_size)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "average_acc = []\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in tscv.split(train_X):\n",
    "    X_tr, X_val = train_X.iloc[train_index], train_X.iloc[test_index]\n",
    "    y_tr, y_val = train_y.iloc[train_index], train_y.iloc[test_index]\n",
    "    \n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # Find the performance info\n",
    "    accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "    precision = metrics.precision_score(y_val, y_pred, zero_division=0)\n",
    "    recall = metrics.recall_score(y_val, y_pred, zero_division=1)\n",
    "    f1 = metrics.f1_score(y_val, y_pred, zero_division=1)\n",
    "    \n",
    "    # Get the performance details\n",
    "    average_acc.append(accuracy)\n",
    "    print(f\"Split: {i}: Accuracy: {accuracy} {precision} {recall} {f1}\")\n",
    "    cm = confusion_matrix(y_val,y_pred)\n",
    "    cr = classification_report(y_val,y_pred)\n",
    "    print(cm)\n",
    "    print(cr)\n",
    "    i+=1\n",
    "    \n",
    "print(\"Average Accuracy: {}\".format(np.mean(average_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cfd0f5d-099e-4d4c-82e4-eb09cfe087dc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
