{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6a6c237-a737-4a91-bc0d-ade5b2e5f124",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "import random\n",
    "import pandas as pd # dataframe manipulation\n",
    "import numpy as np # linear algebra\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "\n",
    "# Configure ssl for unverified content so we can load a dataset from an unknown source (github).\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b350ff1-2082-4328-975a-30224edab440",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Load datasets from local or remote resource:\n",
      "==================================================\n",
      "Training data is local\n",
      "Test data is local\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "#train_url = 'https://raw.githubusercontent.com/bryonbaker/datasets/main/SIT720/Ass3/ac_train_data.csv'\n",
    "train_url = 'https://raw.githubusercontent.com/bryonbaker/datasets/main/SIT720/Ass3/debug_ac_train_data.csv'\n",
    "test_url = 'https://raw.githubusercontent.com/bryonbaker/datasets/main/SIT720/Ass3/ac_test_data.csv'\n",
    "train_path = '/opt/app-root/src/datasets/SIT720/Ass3/ac_train_data.csv'\n",
    "test_path = '/opt/app-root/src/datasets/SIT720/Ass3/ac_test_data.csv'\n",
    "\n",
    "#\n",
    "# Work out if the datasets are local. If not use a remote url. Preference is local.\n",
    "#\n",
    "print(\"Load datasets from local or remote resource:\")\n",
    "print(\"=\"*50)\n",
    "if os.path.isfile(train_path):\n",
    "    print(\"Training data is local\")\n",
    "    training_data = train_path\n",
    "else:\n",
    "    print(\"Training data is remote. Downloading file from: {}\".format(train_url))\n",
    "    training_data = train_url\n",
    "\n",
    "if os.path.isfile(test_path):\n",
    "    print(\"Test data is local\")\n",
    "    test_data = test_path\n",
    "else:\n",
    "    print(\"Test data is remote. Downloading file from: {}\".format(test_url))\n",
    "    test_data = test_url\n",
    "print()\n",
    "\n",
    "# Load the datasets from either local or remote.\n",
    "train_df = pd.read_csv(training_data)\n",
    "test_df = pd.read_csv(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e631d798-4101-4b17-abea-58d295a6a142",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the columns not used in the assignment\n",
    "\n",
    "# Drop the sequence number (column 0) from the test dataset. Column 0 is unlabeled so use the index number.\n",
    "train_df = train_df.drop(train_df.columns[[0]],axis=1)\n",
    "test_df = test_df.drop(test_df.columns[[0]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "58f97a15-cc3c-44c2-b4da-f563dcbe7a78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encode the days of week.\n",
    "\n",
    "oldCol = \"dayofweek\"\n",
    "newCol = \"dayofweeknum\"\n",
    "dayMap = {'Sun' : 0, 'Mon': 1, \"Tue\" : 2, \"Wed\" : 3, \"Thu\" : 4, \"Fri\" : 5, \"Sat\" : 6 }    # How to map the values\n",
    "\n",
    "train_df[newCol] = train_df[oldCol].map(dayMap)    # Adds a new column with proper boolean values\n",
    "train_df = train_df.drop([oldCol], axis=1)    # Drop the old column before renaming the new column to the name just dropped\n",
    "train_df = train_df.rename(columns={newCol : oldCol})\n",
    "      \n",
    "# Ordinal encode the dayof week in the test dataset.\n",
    "test_df[newCol] = test_df[oldCol].map(dayMap)    # Adds a new column with proper boolean values\n",
    "test_df = test_df.drop([oldCol], axis=1)    # Drop the old column before renaming the new column to the name just dropped\n",
    "test_df = test_df.rename(columns={newCol : oldCol})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "991ab3af-cc3b-4e99-8d5d-6e2b84626940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Dataset\n",
      "    load  hourofday    dif  absdif    max       var   entropy  nonlinear  \\\n",
      "0  2.245          0  0.987   0.987  6.215  3.074549  0.678886   0.052903   \n",
      "1  2.259          0  0.014   0.014  6.215  3.172867  0.667450   0.054829   \n",
      "2  2.269          0  0.010   0.010  6.215  3.270112  0.647777   0.056991   \n",
      "3  2.268          0 -0.001   0.001  6.215  3.303763  0.629227   0.057606   \n",
      "4  2.270          0  0.002   0.002  6.215  3.302744  0.621295   0.082640   \n",
      "\n",
      "      hurst  dayofweek  \n",
      "0  0.994071          0  \n",
      "1  0.994154          0  \n",
      "2  0.994220          0  \n",
      "3  0.994150          0  \n",
      "4  0.994041          0  \n",
      "\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: ac, dtype: int64\n",
      "\n",
      "Testing Dataset\n",
      "    load  hourofday    dif  absdif  max  var  entropy  nonlinear  hurst  \\\n",
      "0  1.869          0  0.000   0.000  0.0  0.0      0.0        0.0    0.0   \n",
      "1  1.673          0 -0.196   0.196  0.0  0.0      0.0        0.0    0.0   \n",
      "2  1.660          0 -0.013   0.013  0.0  0.0      0.0        0.0    0.0   \n",
      "3  1.772          0  0.112   0.112  0.0  0.0      0.0        0.0    0.0   \n",
      "4  1.679          0 -0.093   0.093  0.0  0.0      0.0        0.0    0.0   \n",
      "\n",
      "   dayofweek  \n",
      "0          1  \n",
      "1          1  \n",
      "2          1  \n",
      "3          1  \n",
      "4          1  \n",
      "\n",
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: ac, dtype: int64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Split out the X and y from the datasets\n",
    "train_X = train_df.drop(['ac'], axis=1)\n",
    "train_y = train_df[\"ac\"]\n",
    "test_X = test_df.drop(['ac'], axis=1)\n",
    "test_y = test_df['ac']\n",
    "\n",
    "print(\"Training Dataset\")\n",
    "print(f\"{train_X.head()}\\n\")\n",
    "print(f\"{train_y.head()}\\n\")\n",
    "\n",
    "print(\"Testing Dataset\")\n",
    "print(f\"{test_X.head()}\\n\")\n",
    "print(f\"{test_y.head()}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f75d40-16a7-494d-a991-8d989b59ddff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree\n",
    "\n",
    "# Use TimeSeriesSplit. We will make the time series the equivalent of 4 hour periods (even though the back of the data is not continuous)\n",
    "from sklearn.model_selection import TimeSeriesSplit\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Define the split details.\\\n",
    "n_splits = 10\n",
    "test_size = int(train_X.shape[0]/11)\n",
    "print(\"Number of splits: {}\".format(n_splits))\n",
    "\n",
    "tscv = TimeSeriesSplit(n_splits, test_size=test_size)\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "average_acc = []\n",
    "\n",
    "i = 1\n",
    "for train_index, test_index in tscv.split(train_X):\n",
    "    X_tr, X_val = train_X.iloc[train_index], train_X.iloc[test_index]\n",
    "    y_tr, y_val = train_y.iloc[train_index], train_y.iloc[test_index]\n",
    "    \n",
    "    model.fit(X_tr, y_tr)\n",
    "    y_pred = model.predict(X_val)\n",
    "\n",
    "    # Find the performance info\n",
    "    accuracy = metrics.accuracy_score(y_val, y_pred)\n",
    "    precision = metrics.precision_score(y_val, y_pred, zero_division=0)\n",
    "    recall = metrics.recall_score(y_val, y_pred, zero_division=1)\n",
    "    f1 = metrics.f1_score(y_val, y_pred, zero_division=1)\n",
    "    \n",
    "    # Get the performance details\n",
    "    average_acc.append(accuracy)\n",
    "    print(f\"Split: {i}: Accuracy: {accuracy} {precision} {recall} {f1}\")\n",
    "    cm = confusion_matrix(y_val,y_pred)\n",
    "    cr = classification_report(y_val,y_pred)\n",
    "    print(cm)\n",
    "    print(cr)\n",
    "    i+=1\n",
    "    \n",
    "print(\"Average Accuracy: {}\".format(np.mean(average_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6cfd0f5d-099e-4d4c-82e4-eb09cfe087dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = np.arange(100).reshape((50, 2))\n",
    "y = range(50)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c3af44f9-3bcb-43a8-9c2e-82bdf93367c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, shuffle=False, stratify=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "65bcab19-0859-4231-a8eb-e6eaecf29e1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0  1]\n",
      " [ 2  3]\n",
      " [ 4  5]\n",
      " [ 6  7]\n",
      " [ 8  9]\n",
      " [10 11]\n",
      " [12 13]\n",
      " [14 15]\n",
      " [16 17]\n",
      " [18 19]\n",
      " [20 21]\n",
      " [22 23]\n",
      " [24 25]\n",
      " [26 27]\n",
      " [28 29]\n",
      " [30 31]\n",
      " [32 33]\n",
      " [34 35]\n",
      " [36 37]\n",
      " [38 39]\n",
      " [40 41]\n",
      " [42 43]\n",
      " [44 45]\n",
      " [46 47]\n",
      " [48 49]\n",
      " [50 51]\n",
      " [52 53]\n",
      " [54 55]\n",
      " [56 57]\n",
      " [58 59]\n",
      " [60 61]\n",
      " [62 63]\n",
      " [64 65]]\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)\n",
    "print(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ad69295a-815e-4b84-8424-f033b5194722",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[66 67]\n",
      " [68 69]\n",
      " [70 71]\n",
      " [72 73]\n",
      " [74 75]\n",
      " [76 77]\n",
      " [78 79]\n",
      " [80 81]\n",
      " [82 83]\n",
      " [84 85]\n",
      " [86 87]\n",
      " [88 89]\n",
      " [90 91]\n",
      " [92 93]\n",
      " [94 95]\n",
      " [96 97]\n",
      " [98 99]]\n",
      "[33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1bd3e0-d6a9-407b-b76e-3d539b00bbad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
