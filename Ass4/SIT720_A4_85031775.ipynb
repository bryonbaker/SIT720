{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9782f97a-7036-443c-b2b4-ee4009169b32",
   "metadata": {},
   "source": [
    "# Assignment 4\n",
    "* Unit: SIT720\n",
    "* Name: Bryon Baker\n",
    "* Student #: 85031775"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f0dbc90-87da-4bf2-8bad-560d99432f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO BEFORE SUBMISSION:\n",
    "# Increase the train_test_iterations\n",
    "# Uncomment the pip3 installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b2c6859-204a-43bf-a749-6e73d001c86c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install numpy==1.22.3\n",
    "#!pip3 install pandas==1.4.2\n",
    "#!pip3 install scikit-learn==1.0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "84752370-2cdf-4b7d-9131-57beb49ecea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import warnings\n",
    "import random\n",
    "import pandas as pd # dataframe manipulation\n",
    "import numpy as np # linear algebra\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06dc1d27-de7a-450a-ac63-1c735b250bc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Seeding random number generator. Random number is: 0.8444218515250481\n"
     ]
    }
   ],
   "source": [
    "# Seed the random nunmber generator to ensure K-Means randomisation works properly.\n",
    "random.seed(0)\n",
    "\n",
    "# Constant used for train_test_split so there is predicatability across runs\n",
    "global_random_state=11\n",
    "train_test_iterations=10\n",
    "\n",
    "print(f\"Seeding random number generator. Random number is: {random.random()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f83ceca-5da2-472b-90ce-9d519f61a46d",
   "metadata": {},
   "source": [
    "# Helper Functions\n",
    "This section defines any helper functions used in the code below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a3e81e26-3e24-4f5b-ad0e-63adc202ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the inverse of log(x+1) and assign any negative value to zero\n",
    "# As described int he research paper, the inverse log transfor needs to take the inverse of y = ln(x+1). and if y < 0 then y  0\n",
    "def inverse_log_transform( vals ):\n",
    "    vals_x = np.exp(vals)-1\n",
    "    vals_x[vals_x < 0] = 0\n",
    "    \n",
    "    return vals_x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8273895-048d-413a-845e-93e8a413b839",
   "metadata": {},
   "source": [
    "# Standardise the dataset\n",
    "Standardise all values in a dataset such that the mean = 0 and SD = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9c1998a3-91b2-4692-809b-5313d666ab17",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A helper function to standardise all the values in the dataset with a mean=0 and SD=1\n",
    "def standardise_dataset( dataset_name, dataset, column_headings ):\n",
    "    # Standardise all attributes to zero mean and SD 1\n",
    "    scaler = StandardScaler(copy=False, with_mean=True, with_std=True)\n",
    "    scaler.fit(dataset)\n",
    "    result = scaler.transform(dataset)\n",
    "    # print(f\"Transformed Data Frame:\\n{SVM_STFWI_df}\")\n",
    "    m = np.mean(result, axis=0)\n",
    "    s = np.std(result, axis=0)\n",
    "    #print(\"Checking transformation\")\n",
    "    #print(f\"Column  means:\\n{m}\")\n",
    "    #print(f\"Column  SD:\\n{s}\")\n",
    "\n",
    "    # The StandardScaler converts to an array. Convert back to a DataFrame\n",
    "    result_df = pd.DataFrame(result)\n",
    "    result_df.columns = column_headings     # Reassign the column names.\n",
    "    # print(result_df.head())\n",
    "    \n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84c7cbb3-d38b-49d1-8c6e-7c090fda0da1",
   "metadata": {},
   "source": [
    "# Calculate the RMSE\n",
    "Given two series (y and y-hat) take the inverse of a=ln(b+1) for each and replace any negative results with zero. Then calculate the root mean square error for the two series."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eab19132-b5c8-4cad-badb-78b7a876f4b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper to calculate the RMSE\n",
    "def calc_rmse( y, y_hat ):\n",
    "    # Perform the inverse transform of y and h_hat\n",
    "    yy = np.exp(y)-1\n",
    "    yy[yy < 0] = 0\n",
    "    \n",
    "    yy_hat = np.exp(y_hat)-1\n",
    "    yy_hat[yy_hat < 0] = 0\n",
    "        \n",
    "    rmse = mean_squared_error(yy, yy_hat, squared=False)\n",
    "    \n",
    "    return rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d65992-3ff4-427d-8332-bf25feb32986",
   "metadata": {},
   "source": [
    "# Save Datasets\n",
    "This helper creates a local copy of the post-processed datasets.\n",
    "The function has been commented out for final assignment submission in case the local filesystem write causes the notebook to crash and get a zero mark."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b2c43868-ac67-4ff5-8767-a6627f52bb8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path \n",
    "\n",
    "\n",
    "def save_dataset( filename, dataset ):\n",
    "    return   # This is bypassed for the final assignment submission in case this causes the notbook to crash on a different machine\n",
    "    file_dir = \"~/datasets/SIT720/Ass4/transformed/\"\n",
    "    filepath = Path(file_dir)  \n",
    "    filepath.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    full_filename = file_dir + filename + \".csv\"\n",
    "    dataset.to_csv(full_filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b050e0d2-3d78-4c41-bf95-67e8770fc0b0",
   "metadata": {},
   "source": [
    "# Load the source dataset\n",
    "Dataset is stored in public git repo. COnfigure the ssl context in order to access github raw data files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef98a5ad-32d1-4920-abd5-1f6dbff4c7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   X  Y month  day  FFMC   DMC     DC  ISI  temp  RH  wind  rain  area\n",
      "0  7  5   mar  fri  86.2  26.2   94.3  5.1   8.2  51   6.7   0.0   0.0\n",
      "1  7  4   oct  tue  90.6  35.4  669.1  6.7  18.0  33   0.9   0.0   0.0\n",
      "2  7  4   oct  sat  90.6  43.7  686.9  6.7  14.6  33   1.3   0.0   0.0\n",
      "3  8  6   mar  fri  91.7  33.3   77.5  9.0   8.3  97   4.0   0.2   0.0\n",
      "4  8  6   mar  sun  89.3  51.3  102.2  9.6  11.4  99   1.8   0.0   0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "url = 'https://raw.githubusercontent.com/bryonbaker/datasets/main/SIT720/Ass4/forestfires.csv'\n",
    "full_df = pd.read_csv(url)\n",
    "print(f\"{full_df.head()}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbe2af36-d3b0-42d2-8a96-3525546dd458",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "Read the article and reproduce the RMSE results presented in Table 3 using Python modules and packages (including your own script or customised codes). Write a report summarising the dataset, used ML methods, experiment protocol and results including variations, if any. During reproducing the results:               (15 Marks)\n",
    "\n",
    "1. you should use the same set of features used by the authors.\n",
    "2. you should use the same classifier with exact parameter values.\n",
    "3. you should use the same training/test splitting approach as used by the authors.\n",
    "4. you should use the same pre/post processing, if any, used by the authors.\n",
    "5. you should report the same performance metric (RMSE) as shown in Table 3."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9903646d-77db-46be-b1e1-6af1c6723b06",
   "metadata": {},
   "source": [
    "# Pre Process the Data\n",
    "1. One hot encode the day and month attributes.\n",
    "2. Ordinal encode the day/month for DT, MR, RF\n",
    "3. Transform the area to be y = ln(area+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1141cd28-eb72-4577-89ac-e8b77fa41504",
   "metadata": {},
   "source": [
    "## Preprocess area\n",
    "Reduce the skewness of area as per procedure on page 5.\n",
    "This will be used to train the model, but it is important to take the inverse log after prediction so as to find the predicted area. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1796b57c-cf1f-43d6-906a-c9118d918223",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data does not have any missing values.\n"
     ]
    }
   ],
   "source": [
    "# Check the dataset has no NaNs.\n",
    "if full_df.isnull().sum().sum() == 0:\n",
    "    print(\"Data does not have any missing values.\")\n",
    "else:\n",
    "    print(\"Data has missing values and needs pre processing.\")\n",
    "    print(\"Stopping....\")\n",
    "    quit() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9909a634-a5e7-41ff-b141-4df2e1e69ec9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   area  xfrmd_area\n",
      "0   0.0         1.0\n",
      "1   0.0         1.0\n",
      "2   0.0         1.0\n",
      "3   0.0         1.0\n",
      "4   0.0         1.0\n",
      "   area  xfrmd_area\n",
      "0   0.0         0.0\n",
      "1   0.0         0.0\n",
      "2   0.0         0.0\n",
      "3   0.0         0.0\n",
      "4   0.0         0.0\n"
     ]
    }
   ],
   "source": [
    "# Create a new area feature and calculate the values as new-area = ln(area+1)\n",
    "area_df = pd.DataFrame(full_df[\"area\"])\n",
    "area_df[\"xfrmd_area\"] = full_df[\"area\"] +1                 # Create a new area column that will contain the ln(area+1)\n",
    "print(area_df.head())\n",
    "area_df[\"xfrmd_area\"] = np.log(area_df['xfrmd_area'])      # Take the ln(area+1)\n",
    "print(area_df.head()) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eec2cb0-808b-4290-a003-2fae7c78f205",
   "metadata": {},
   "source": [
    "### 1-of-C Encoding\n",
    "\n",
    "Perform 1-of-C encoding on the day and month features. These will be used tor SVM, NN, and MR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "99d61bb3-0d93-444b-8211-8066bfa96dec",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', drop=None, dtype='int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9eb6b4bb-0c1a-419f-9c5a-ec369c45c82e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One-hot encode month\n",
    "transformed = ohe.fit_transform(full_df[['month']])\n",
    "ohe_month_df = pd.DataFrame(transformed.toarray())\n",
    "ohe_month_df.columns = ohe.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "502d4ab4-a988-4918-8ef8-83a7bfc29aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One hot encode day\n",
    "transformed = ohe.fit_transform(full_df[['day']])\n",
    "ohe_day_df = pd.DataFrame(transformed.toarray())\n",
    "ohe_day_df.columns = ohe.categories_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b83141eb-b702-4cbe-8f08-0ff09ac8f466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>...</th>\n",
       "      <th>nov</th>\n",
       "      <th>oct</th>\n",
       "      <th>sep</th>\n",
       "      <th>fri</th>\n",
       "      <th>mon</th>\n",
       "      <th>sat</th>\n",
       "      <th>sun</th>\n",
       "      <th>thu</th>\n",
       "      <th>tue</th>\n",
       "      <th>wed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>92.3</td>\n",
       "      <td>85.3</td>\n",
       "      <td>488.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>29</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>92.3</td>\n",
       "      <td>88.9</td>\n",
       "      <td>495.6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>24.1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>91.5</td>\n",
       "      <td>145.4</td>\n",
       "      <td>608.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>91.0</td>\n",
       "      <td>129.5</td>\n",
       "      <td>692.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>63</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>92.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>698.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>22.8</td>\n",
       "      <td>40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>92.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>698.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>51</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>92.8</td>\n",
       "      <td>73.2</td>\n",
       "      <td>713.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>63.5</td>\n",
       "      <td>70.8</td>\n",
       "      <td>665.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>90.9</td>\n",
       "      <td>126.5</td>\n",
       "      <td>686.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>42</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>92.9</td>\n",
       "      <td>133.3</td>\n",
       "      <td>699.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>26.4</td>\n",
       "      <td>21</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>93.3</td>\n",
       "      <td>141.2</td>\n",
       "      <td>713.9</td>\n",
       "      <td>13.9</td>\n",
       "      <td>22.9</td>\n",
       "      <td>44</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>91.7</td>\n",
       "      <td>35.8</td>\n",
       "      <td>80.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>15.1</td>\n",
       "      <td>27</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>84.9</td>\n",
       "      <td>32.8</td>\n",
       "      <td>664.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>47</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>89.2</td>\n",
       "      <td>27.9</td>\n",
       "      <td>70.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>35</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>86.3</td>\n",
       "      <td>27.4</td>\n",
       "      <td>97.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.3</td>\n",
       "      <td>44</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    X  Y  FFMC    DMC     DC   ISI  temp  RH  wind  rain  ...  nov  oct  sep  \\\n",
       "0   7  5  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0  ...    0    0    0   \n",
       "1   7  4  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0  ...    0    1    0   \n",
       "2   7  4  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0  ...    0    1    0   \n",
       "3   8  6  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2  ...    0    0    0   \n",
       "4   8  6  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0  ...    0    0    0   \n",
       "5   8  6  92.3   85.3  488.0  14.7  22.2  29   5.4   0.0  ...    0    0    0   \n",
       "6   8  6  92.3   88.9  495.6   8.5  24.1  27   3.1   0.0  ...    0    0    0   \n",
       "7   8  6  91.5  145.4  608.2  10.7   8.0  86   2.2   0.0  ...    0    0    0   \n",
       "8   8  6  91.0  129.5  692.6   7.0  13.1  63   5.4   0.0  ...    0    0    1   \n",
       "9   7  5  92.5   88.0  698.6   7.1  22.8  40   4.0   0.0  ...    0    0    1   \n",
       "10  7  5  92.5   88.0  698.6   7.1  17.8  51   7.2   0.0  ...    0    0    1   \n",
       "11  7  5  92.8   73.2  713.0  22.6  19.3  38   4.0   0.0  ...    0    0    1   \n",
       "12  6  5  63.5   70.8  665.3   0.8  17.0  72   6.7   0.0  ...    0    0    0   \n",
       "13  6  5  90.9  126.5  686.5   7.0  21.3  42   2.2   0.0  ...    0    0    1   \n",
       "14  6  5  92.9  133.3  699.6   9.2  26.4  21   4.5   0.0  ...    0    0    1   \n",
       "15  6  5  93.3  141.2  713.9  13.9  22.9  44   5.4   0.0  ...    0    0    1   \n",
       "16  5  5  91.7   35.8   80.8   7.8  15.1  27   5.4   0.0  ...    0    0    0   \n",
       "17  8  5  84.9   32.8  664.2   3.0  16.7  47   4.9   0.0  ...    0    1    0   \n",
       "18  6  4  89.2   27.9   70.8   6.3  15.9  35   4.0   0.0  ...    0    0    0   \n",
       "19  6  4  86.3   27.4   97.1   5.1   9.3  44   4.5   0.0  ...    0    0    0   \n",
       "\n",
       "    fri  mon  sat  sun  thu  tue  wed  \n",
       "0     1    0    0    0    0    0    0  \n",
       "1     0    0    0    0    0    1    0  \n",
       "2     0    0    1    0    0    0    0  \n",
       "3     1    0    0    0    0    0    0  \n",
       "4     0    0    0    1    0    0    0  \n",
       "5     0    0    0    1    0    0    0  \n",
       "6     0    1    0    0    0    0    0  \n",
       "7     0    1    0    0    0    0    0  \n",
       "8     0    0    0    0    0    1    0  \n",
       "9     0    0    1    0    0    0    0  \n",
       "10    0    0    1    0    0    0    0  \n",
       "11    0    0    1    0    0    0    0  \n",
       "12    1    0    0    0    0    0    0  \n",
       "13    0    1    0    0    0    0    0  \n",
       "14    0    0    0    0    0    0    1  \n",
       "15    1    0    0    0    0    0    0  \n",
       "16    0    0    1    0    0    0    0  \n",
       "17    0    1    0    0    0    0    0  \n",
       "18    0    0    0    0    0    0    1  \n",
       "19    0    0    1    0    0    0    0  \n",
       "\n",
       "[20 rows x 29 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoded_df holds all the training.test data that has been 1-of-C encoded.\n",
    "ohe_encoded_df = full_df.drop(['month','day','area'], axis=1)\n",
    "ohe_encoded_df = pd.concat([ohe_encoded_df, ohe_month_df], axis=1)\n",
    "ohe_encoded_df = pd.concat([ohe_encoded_df, ohe_day_df], axis=1)\n",
    "ohe_encoded_df.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5055836-656c-44d7-bd71-79aa894d58f6",
   "metadata": {},
   "source": [
    "### Ordinal Encoding\n",
    "\n",
    "Perform ordinal encoding of day and month. These will be used for RF, and DT models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "feba921a-2472-477b-a7b7-5aa63f6a8fe1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encode month\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ore = OrdinalEncoder(dtype='int')\n",
    "\n",
    "transformed = ore.fit_transform(full_df[['month']])\n",
    "ord_month_df = pd.DataFrame(transformed)\n",
    "ord_month_df.columns = ['month']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "277fea81-bdce-4e87-bbbd-0d4b9911b08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordinal encode month\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "ore = OrdinalEncoder(dtype='int')\n",
    "\n",
    "transformed = ore.fit_transform(full_df[['day']])\n",
    "ord_day_df = pd.DataFrame(transformed)\n",
    "ord_day_df.columns = ['day']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43447900-3999-45b6-b624-41fd8d319a64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X</th>\n",
       "      <th>Y</th>\n",
       "      <th>FFMC</th>\n",
       "      <th>DMC</th>\n",
       "      <th>DC</th>\n",
       "      <th>ISI</th>\n",
       "      <th>temp</th>\n",
       "      <th>RH</th>\n",
       "      <th>wind</th>\n",
       "      <th>rain</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>86.2</td>\n",
       "      <td>26.2</td>\n",
       "      <td>94.3</td>\n",
       "      <td>5.1</td>\n",
       "      <td>8.2</td>\n",
       "      <td>51</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>90.6</td>\n",
       "      <td>35.4</td>\n",
       "      <td>669.1</td>\n",
       "      <td>6.7</td>\n",
       "      <td>18.0</td>\n",
       "      <td>33</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>90.6</td>\n",
       "      <td>43.7</td>\n",
       "      <td>686.9</td>\n",
       "      <td>6.7</td>\n",
       "      <td>14.6</td>\n",
       "      <td>33</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>91.7</td>\n",
       "      <td>33.3</td>\n",
       "      <td>77.5</td>\n",
       "      <td>9.0</td>\n",
       "      <td>8.3</td>\n",
       "      <td>97</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>89.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>102.2</td>\n",
       "      <td>9.6</td>\n",
       "      <td>11.4</td>\n",
       "      <td>99</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>92.3</td>\n",
       "      <td>85.3</td>\n",
       "      <td>488.0</td>\n",
       "      <td>14.7</td>\n",
       "      <td>22.2</td>\n",
       "      <td>29</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>92.3</td>\n",
       "      <td>88.9</td>\n",
       "      <td>495.6</td>\n",
       "      <td>8.5</td>\n",
       "      <td>24.1</td>\n",
       "      <td>27</td>\n",
       "      <td>3.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>91.5</td>\n",
       "      <td>145.4</td>\n",
       "      <td>608.2</td>\n",
       "      <td>10.7</td>\n",
       "      <td>8.0</td>\n",
       "      <td>86</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>91.0</td>\n",
       "      <td>129.5</td>\n",
       "      <td>692.6</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.1</td>\n",
       "      <td>63</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>92.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>698.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>22.8</td>\n",
       "      <td>40</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>92.5</td>\n",
       "      <td>88.0</td>\n",
       "      <td>698.6</td>\n",
       "      <td>7.1</td>\n",
       "      <td>17.8</td>\n",
       "      <td>51</td>\n",
       "      <td>7.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>92.8</td>\n",
       "      <td>73.2</td>\n",
       "      <td>713.0</td>\n",
       "      <td>22.6</td>\n",
       "      <td>19.3</td>\n",
       "      <td>38</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>63.5</td>\n",
       "      <td>70.8</td>\n",
       "      <td>665.3</td>\n",
       "      <td>0.8</td>\n",
       "      <td>17.0</td>\n",
       "      <td>72</td>\n",
       "      <td>6.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>90.9</td>\n",
       "      <td>126.5</td>\n",
       "      <td>686.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>21.3</td>\n",
       "      <td>42</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>92.9</td>\n",
       "      <td>133.3</td>\n",
       "      <td>699.6</td>\n",
       "      <td>9.2</td>\n",
       "      <td>26.4</td>\n",
       "      <td>21</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>93.3</td>\n",
       "      <td>141.2</td>\n",
       "      <td>713.9</td>\n",
       "      <td>13.9</td>\n",
       "      <td>22.9</td>\n",
       "      <td>44</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>91.7</td>\n",
       "      <td>35.8</td>\n",
       "      <td>80.8</td>\n",
       "      <td>7.8</td>\n",
       "      <td>15.1</td>\n",
       "      <td>27</td>\n",
       "      <td>5.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>84.9</td>\n",
       "      <td>32.8</td>\n",
       "      <td>664.2</td>\n",
       "      <td>3.0</td>\n",
       "      <td>16.7</td>\n",
       "      <td>47</td>\n",
       "      <td>4.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>89.2</td>\n",
       "      <td>27.9</td>\n",
       "      <td>70.8</td>\n",
       "      <td>6.3</td>\n",
       "      <td>15.9</td>\n",
       "      <td>35</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>86.3</td>\n",
       "      <td>27.4</td>\n",
       "      <td>97.1</td>\n",
       "      <td>5.1</td>\n",
       "      <td>9.3</td>\n",
       "      <td>44</td>\n",
       "      <td>4.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    X  Y  FFMC    DMC     DC   ISI  temp  RH  wind  rain  month  day\n",
       "0   7  5  86.2   26.2   94.3   5.1   8.2  51   6.7   0.0      7    0\n",
       "1   7  4  90.6   35.4  669.1   6.7  18.0  33   0.9   0.0     10    5\n",
       "2   7  4  90.6   43.7  686.9   6.7  14.6  33   1.3   0.0     10    2\n",
       "3   8  6  91.7   33.3   77.5   9.0   8.3  97   4.0   0.2      7    0\n",
       "4   8  6  89.3   51.3  102.2   9.6  11.4  99   1.8   0.0      7    3\n",
       "5   8  6  92.3   85.3  488.0  14.7  22.2  29   5.4   0.0      1    3\n",
       "6   8  6  92.3   88.9  495.6   8.5  24.1  27   3.1   0.0      1    1\n",
       "7   8  6  91.5  145.4  608.2  10.7   8.0  86   2.2   0.0      1    1\n",
       "8   8  6  91.0  129.5  692.6   7.0  13.1  63   5.4   0.0     11    5\n",
       "9   7  5  92.5   88.0  698.6   7.1  22.8  40   4.0   0.0     11    2\n",
       "10  7  5  92.5   88.0  698.6   7.1  17.8  51   7.2   0.0     11    2\n",
       "11  7  5  92.8   73.2  713.0  22.6  19.3  38   4.0   0.0     11    2\n",
       "12  6  5  63.5   70.8  665.3   0.8  17.0  72   6.7   0.0      1    0\n",
       "13  6  5  90.9  126.5  686.5   7.0  21.3  42   2.2   0.0     11    1\n",
       "14  6  5  92.9  133.3  699.6   9.2  26.4  21   4.5   0.0     11    6\n",
       "15  6  5  93.3  141.2  713.9  13.9  22.9  44   5.4   0.0     11    0\n",
       "16  5  5  91.7   35.8   80.8   7.8  15.1  27   5.4   0.0      7    2\n",
       "17  8  5  84.9   32.8  664.2   3.0  16.7  47   4.9   0.0     10    1\n",
       "18  6  4  89.2   27.9   70.8   6.3  15.9  35   4.0   0.0      7    6\n",
       "19  6  4  86.3   27.4   97.1   5.1   9.3  44   4.5   0.0      0    2"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ord_encoded_df = full_df     # RF and DT need the ordinal encoded dataframe\n",
    "ord_encoded_df = full_df.drop(['month','day','area'], axis=1)\n",
    "ord_encoded_df = pd.concat([ord_encoded_df, ord_month_df], axis=1)\n",
    "ord_encoded_df = pd.concat([ord_encoded_df, ord_day_df], axis=1)\n",
    "ord_encoded_df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "961b9089-ee02-4e14-b986-6b0103f2b608",
   "metadata": {},
   "outputs": [],
   "source": [
    "del full_df         # Make sure we don't accidentally use full_df later"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c4d1871-dd52-4cb3-983c-938f5e9f9606",
   "metadata": {},
   "source": [
    "## Create Sub-Datasets\n",
    "\n",
    "Now we have all the raw ingredients for all datasets, create the sub datasets that the different models will need.\n",
    "\n",
    "Although some of the sataset requirements are the same across models, the approach taken in this assignment is to have four datasets per model. This approach was chosen just in case there was a need to further pre-process the datasets uniquely for a given model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1d01f7a6-4de4-45a2-92c5-85fd226cb57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the sub datasets from the transformed dataset\n",
    "\n",
    "# Get the 1-of-C encoded column names for month and day\n",
    "month_cols = ohe_month_df.columns.tolist()\n",
    "day_cols = ohe_day_df.columns.tolist()\n",
    "\n",
    "# Construct the dataframe column names\n",
    "STFWI_ohe_encoded_cols = ['X','Y','FFMC','DMC','DC','ISI']\n",
    "STFWI_ohe_encoded_cols = STFWI_ohe_encoded_cols + month_cols + day_cols\n",
    "STM_ohe_encoded_cols = ['X','Y','temp','RH','wind','rain']\n",
    "STM_ohe_encoded_cols = STM_ohe_encoded_cols + month_cols + day_cols\n",
    "FWI_ohe_encoded_cols = ['FFMC','DMC','DC','ISI']\n",
    "M_ohe_encoded_cols = ['temp','RH','wind','rain']\n",
    "\n",
    "# Construct the dataframe column names\n",
    "STFWI_ord_encoded_cols = ['X','Y','month','day','FFMC','DMC','DC','ISI']\n",
    "STM_ord_encoded_cols = ['X','Y','month','day','temp','RH','wind','rain']\n",
    "FWI_ord_encoded_cols = ['FFMC','DMC','DC','ISI']\n",
    "M_ord_encoded_cols = ['temp','RH','wind','rain']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "053d0293-e19f-46f5-a009-f1058b264daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create feature tables for MR, SVM, and NN\n",
    "STFWI_ohe_encoded_df = ohe_encoded_df[STFWI_ohe_encoded_cols]\n",
    "STM_ohe_encoded_df = ohe_encoded_df[STM_ohe_encoded_cols]\n",
    "FWI_ohe_encoded_df = ohe_encoded_df[FWI_ohe_encoded_cols]\n",
    "M_ohe_encoded_df = ohe_encoded_df[M_ohe_encoded_cols]\n",
    "\n",
    "# Create the feature tables for RF and DT\n",
    "STFWI_ord_encoded_df = ord_encoded_df[STFWI_ord_encoded_cols]\n",
    "STM_ord_encoded_df = ord_encoded_df[STM_ord_encoded_cols]\n",
    "FWI_ord_encoded_df = ord_encoded_df[FWI_ord_encoded_cols]\n",
    "M_ord_encoded_df = ord_encoded_df[M_ord_encoded_cols]\n",
    "\n",
    "# Create the transformed area ln(area+1)\n",
    "y_xformed = area_df[\"xfrmd_area\"]\n",
    "y_vanilla = area_df[\"area\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "04c55c0e-31e6-476f-9bc4-79d3b8e03d7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM, MR, and NN Dataset columns:\n",
      "================\n",
      "STFWI Dataset columns:\n",
      "Index(['X', 'Y', 'FFMC', 'DMC', 'DC', 'ISI', 'apr', 'aug', 'dec', 'feb', 'jan',\n",
      "       'jul', 'jun', 'mar', 'may', 'nov', 'oct', 'sep', 'fri', 'mon', 'sat',\n",
      "       'sun', 'thu', 'tue', 'wed'],\n",
      "      dtype='object')\n",
      "\n",
      "STM Dataset columns:\n",
      "Index(['X', 'Y', 'temp', 'RH', 'wind', 'rain', 'apr', 'aug', 'dec', 'feb',\n",
      "       'jan', 'jul', 'jun', 'mar', 'may', 'nov', 'oct', 'sep', 'fri', 'mon',\n",
      "       'sat', 'sun', 'thu', 'tue', 'wed'],\n",
      "      dtype='object')\n",
      "\n",
      "FWI Dataset columns:\n",
      "Index(['FFMC', 'DMC', 'DC', 'ISI'], dtype='object')\n",
      "\n",
      "M Dataset columns:\n",
      "Index(['temp', 'RH', 'wind', 'rain'], dtype='object')\n",
      "\n",
      "================\n",
      "DT and RF Dataset columns:\n",
      "================\n",
      "STFWI Dataset columns:\n",
      "Index(['X', 'Y', 'month', 'day', 'FFMC', 'DMC', 'DC', 'ISI'], dtype='object')\n",
      "\n",
      "STM Dataset columns:\n",
      "Index(['X', 'Y', 'month', 'day', 'temp', 'RH', 'wind', 'rain'], dtype='object')\n",
      "\n",
      "FWI Dataset columns:\n",
      "Index(['FFMC', 'DMC', 'DC', 'ISI'], dtype='object')\n",
      "\n",
      "M Dataset columns:\n",
      "Index(['temp', 'RH', 'wind', 'rain'], dtype='object')\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Display which columns are used for which datasets.\n",
    "print(\"SVM, MR, and NN Dataset columns:\")\n",
    "print(\"=\"*16)\n",
    "print(f\"STFWI Dataset columns:\\n{STFWI_ohe_encoded_df.columns}\\n\")\n",
    "print(f\"STM Dataset columns:\\n{STM_ohe_encoded_df.columns}\\n\")\n",
    "print(f\"FWI Dataset columns:\\n{FWI_ohe_encoded_df.columns}\\n\")\n",
    "print(f\"M Dataset columns:\\n{M_ohe_encoded_df.columns}\\n\")\n",
    "print(\"=\"*16)\n",
    "print(\"DT and RF Dataset columns:\")\n",
    "print(\"=\"*16)\n",
    "print(f\"STFWI Dataset columns:\\n{STFWI_ord_encoded_df.columns}\\n\")\n",
    "print(f\"STM Dataset columns:\\n{STM_ord_encoded_df.columns}\\n\")\n",
    "print(f\"FWI Dataset columns:\\n{FWI_ord_encoded_df.columns}\\n\")\n",
    "print(f\"M Dataset columns:\\n{M_ord_encoded_df.columns}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9ddd8c-11e3-46f8-a6c6-66adb3c421c6",
   "metadata": {},
   "source": [
    "## Decision Tree Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6e08970c-40e1-4885-9509-316a3be6c009",
   "metadata": {},
   "outputs": [],
   "source": [
    "DT_STFWI_df = STFWI_ord_encoded_df\n",
    "DT_STM_df = STM_ord_encoded_df\n",
    "DT_FWI_df = FWI_ord_encoded_df\n",
    "DT_M_df = M_ord_encoded_df\n",
    "\n",
    "save_dataset( \"DT_STFWI_df\", DT_STFWI_df )\n",
    "save_dataset( \"DT_STM_df\", DT_STM_df )\n",
    "save_dataset( \"DT_FWI_df\", DT_FWI_df )\n",
    "save_dataset( \"DT_M_df\", DT_M_df )\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93d38183-51b0-47b2-8138-e3f72350bc07",
   "metadata": {},
   "source": [
    "## Random Forrest Dataset Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "577b3ae3-5285-4220-9509-ca406e80a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "RF_STFWI_df = STFWI_ord_encoded_df\n",
    "RF_STM_df = STM_ord_encoded_df\n",
    "RF_FWI_df = FWI_ord_encoded_df\n",
    "RF_M_df = M_ord_encoded_df\n",
    "\n",
    "# Save the dataset to a file for manual exploration and verifiaction of feature engineering.\n",
    "save_dataset( \"RF_STFWI_df\", RF_STFWI_df )\n",
    "save_dataset( \"RF_STM_df\", RF_STM_df )\n",
    "save_dataset( \"RF_FWI_df\", RF_FWI_df )\n",
    "save_dataset( \"RF_M_df\", RF_M_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6291986-637a-4c5f-95c2-8badda2dd2b8",
   "metadata": {},
   "source": [
    "## SVM Data Set Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f7895b0d-8f9f-4ccf-84c5-b7b4b9442581",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardise all attributes to zero mean and SD 1\n",
    "SVM_STFWI_df = STFWI_ohe_encoded_df\n",
    "SVM_STM_df = STM_ohe_encoded_df\n",
    "SVM_FWI_df = FWI_ohe_encoded_df\n",
    "SVM_M_df = M_ohe_encoded_df\n",
    "\n",
    "SVM_STFWI_df = standardise_dataset(\"SVM_STFWI_df\", SVM_STFWI_df, STFWI_ohe_encoded_cols)\n",
    "SVM_STM_df = standardise_dataset(\"SVM_STM_df\", SVM_STM_df, STM_ohe_encoded_cols)\n",
    "SVM_FWI_df = standardise_dataset(\"SVM_FWI_df\", SVM_FWI_df, FWI_ohe_encoded_cols)\n",
    "SVM_M_df = standardise_dataset(\"SVM_M_df\", SVM_M_df, M_ohe_encoded_cols)\n",
    "\n",
    "# Save the dataset to a file for manual exploration and verifiaction of feature engineering.\n",
    "save_dataset( \"SVM_STFWI_df\", SVM_STFWI_df )\n",
    "save_dataset( \"SVM_STM_df\", SVM_STM_df )\n",
    "save_dataset( \"SVM_FWI_df\", SVM_FWI_df )\n",
    "save_dataset( \"SVM_M_df\", SVM_M_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a7c337-56da-4084-b45a-c87f22a961bc",
   "metadata": {},
   "source": [
    "## Multiple Rgression Data Set Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "189140c9-e937-4aa5-af58-9c6b3cceb75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "MR_STFWI_df = STFWI_ohe_encoded_df\n",
    "MR_STM_df = STM_ohe_encoded_df\n",
    "MR_FWI_df = FWI_ohe_encoded_df\n",
    "MR_M_df = M_ohe_encoded_df\n",
    "\n",
    "MR_STFWI_df = standardise_dataset(\"MR_STFWI_df\", MR_STFWI_df, STFWI_ohe_encoded_cols)\n",
    "MR_STM_df = standardise_dataset(\"MR_STM_df\", MR_STM_df, STM_ohe_encoded_cols)\n",
    "MR_FWI_df = standardise_dataset(\"MR_FWI_df\", MR_FWI_df, FWI_ohe_encoded_cols)\n",
    "MR_M_df = standardise_dataset(\"MR_M_df\", MR_M_df, M_ohe_encoded_cols)\n",
    "\n",
    "# Save the dataset to a file for manual exploration and verifiaction of feature engineering.\n",
    "save_dataset( \"MR_STFWI_df\", MR_STFWI_df )\n",
    "save_dataset( \"MR_STM_df\", MR_STM_df )\n",
    "save_dataset( \"MR_FWI_df\", MR_FWI_df )\n",
    "save_dataset( \"MR_M_df\", MR_M_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb4c8a2-4aeb-4165-8470-829f915757ae",
   "metadata": {},
   "source": [
    "# Create the Results DataFrame\n",
    "\n",
    "This dataframe will contain all of the results for the assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "85339eec-6af7-4080-9ad4-3d76844da5bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Model','STFWI (RMSE)','STM (RMSE)','FWI (RMSE)','M (RMSE)'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33aa1237-54d6-47d8-b717-2bef785dbd29",
   "metadata": {},
   "source": [
    "# Calculate the Naive results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a8ebd366-c6dd-4613-907e-aecbd59579f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate an array with the predicted values being the mean of the area\n",
    "y = area_df[\"area\"]\n",
    "y_pred = np.mean(y)\n",
    "y_naive_pred = np.repeat(y_pred, len(y))\n",
    "\n",
    "# Calculate the naive RMSE\n",
    "naive_rmse = mean_squared_error(y, y_naive_pred, squared=False)\n",
    "#print(naive_rmse)\n",
    "\n",
    "# Add the naive results to the Results Table\n",
    "rmse_df = pd.DataFrame([['Naive', naive_rmse, naive_rmse, naive_rmse, naive_rmse]], columns=['Model','STFWI (RMSE)','STM (RMSE)','FWI (RMSE)','M (RMSE)'])\n",
    "#results_df = results_df.append(rmse_df)\n",
    "results_df = pd.concat([results_df, rmse_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "739335c1-32f7-4a51-8c63-41fe96f34001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>STFWI (RMSE)</th>\n",
       "      <th>STM (RMSE)</th>\n",
       "      <th>FWI (RMSE)</th>\n",
       "      <th>M (RMSE)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive</td>\n",
       "      <td>63.594226</td>\n",
       "      <td>63.594226</td>\n",
       "      <td>63.594226</td>\n",
       "      <td>63.594226</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model STFWI (RMSE) STM (RMSE) FWI (RMSE)   M (RMSE)\n",
       "0  Naive    63.594226  63.594226  63.594226  63.594226"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a4a384e-3fdc-4b55-85c7-9d312454a48c",
   "metadata": {},
   "source": [
    "# Decision Tree\n",
    "\n",
    "Scoring details:\n",
    "\n",
    "RMSE: https://scikit-learn.org/stable/modules/model_evaluation.html\n",
    "\n",
    "https://stackoverflow.com/questions/62514395/score-obtained-from-cross-val-score-is-rmse-or-mse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7159c377-4ec4-4446-8f8f-7e2acde5dd92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DECISION TREE\n",
      "******************************\n",
      "Train/Test running for 10 iterations.\n",
      "==========\n",
      "STFWI\n",
      "RMSE: 33.36797772613939\n",
      "==========\n",
      "STM\n",
      "RMSE: 44.667739854613714\n",
      "==========\n",
      "FWI\n",
      "RMSE: 33.079516673420585\n",
      "==========\n",
      "M\n",
      "RMSE: 56.09609903900008\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "print(\"DECISION TREE\")\n",
    "print(\"*\"*30)\n",
    "\n",
    "# Get the list of training / validating datasets\n",
    "train_set = { \"STFWI\" : DT_STFWI_df, \"STM\" : DT_STM_df, \"FWI\" : DT_FWI_df, \"M\" : DT_M_df}\n",
    "\n",
    "rmse_score = []\n",
    "\n",
    "print(f\"Train/Test running for {train_test_iterations} iterations.\")\n",
    "\n",
    "# Iterate over each dataset, fit the mode and evaluate the performance with RMSE\n",
    "for key in train_set:\n",
    "    print(\"=\"*10)\n",
    "    print(key)\n",
    "\n",
    "    # Run 10 train / test splits and take the average RMSE for each dataset\n",
    "    results = []\n",
    "    for run in range(train_test_iterations):\n",
    "        # Split the dataset for train/test\n",
    "        X_train, X_test, y_train, y_test = train_test_split( train_set[key], y_xformed, test_size=0.10, random_state=8)\n",
    "\n",
    "        # Set hyperparameters according to the research paper\n",
    "        # min_samples_split = 2\n",
    "        model = DecisionTreeRegressor(random_state=1, min_samples_split = 2)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        rmse = calc_rmse( y_pred, y_test )\n",
    "        results.append(rmse)\n",
    "\n",
    "    avg = sum(results) / len(results)\n",
    "    rmse_score.append(round(avg,1))\n",
    "    # print(results)\n",
    "    print(f\"RMSE: {avg}\")\n",
    "\n",
    "rmse_df = pd.DataFrame([['DT', rmse_score[0], rmse_score[1], rmse_score[2], rmse_score[3]]], columns=['Model','STFWI (RMSE)','STM (RMSE)','FWI (RMSE)','M (RMSE)'])\n",
    "#results_df = results_df.append(rmse_df)\n",
    "results_df = pd.concat([results_df, rmse_df])\n",
    "    \n",
    "del rmse_score, train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d77342-44a4-46eb-a740-15f3ace2d86b",
   "metadata": {},
   "source": [
    "# Random Forrest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1b597236-9f71-4827-90f6-3222efb624b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM FORREST\n",
      "******************************\n",
      "Train/Test running for 10 iterations.\n",
      "STFWI\n",
      "==========\n",
      "RMSE: 32.699069995938146\n",
      "STM\n",
      "==========\n",
      "RMSE: 32.40763807823598\n",
      "FWI\n",
      "==========\n",
      "RMSE: 32.721179350330246\n",
      "M\n",
      "==========\n",
      "RMSE: 32.36444927022474\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "print(\"RANDOM FORREST\")\n",
    "print(\"*\"*30)\n",
    "\n",
    "\n",
    "# Get the list of training / validating datasets\n",
    "train_set = { \"STFWI\" : RF_STFWI_df, \"STM\" : RF_STM_df, \"FWI\" : RF_FWI_df, \"M\" : RF_M_df}\n",
    "\n",
    "rmse_score = []\n",
    "\n",
    "print(f\"Train/Test running for {train_test_iterations} iterations.\")\n",
    "\n",
    "for key in train_set:\n",
    "    print(key)\n",
    "    print(\"=\"*10)\n",
    "    \n",
    "    # Run 10 train / test splits and take the average RMSE for each dataset\n",
    "    results = []\n",
    "    for run in range(train_test_iterations):\n",
    "        # Split the dataset for train/test\n",
    "        X_train, X_test, y_train, y_test = train_test_split( train_set[key], y_xformed, test_size=0.10, random_state=8)\n",
    "\n",
    "        # Set hyperparameters according to research paper\n",
    "        # Number of trees: 500\n",
    "        model = RandomForestRegressor(random_state=1, n_estimators = 500)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        rmse = calc_rmse( y_pred, y_test )\n",
    "        results.append(rmse)\n",
    "    \n",
    "    avg = sum(results) / len(results)\n",
    "    rmse_score.append(round(avg,1))\n",
    "    # print(results)\n",
    "    print(f\"RMSE: {avg}\")\n",
    "\n",
    "    \n",
    "rmse_df = pd.DataFrame([['RF', rmse_score[0], rmse_score[1], rmse_score[2], rmse_score[3]]], columns=['Model','STFWI (RMSE)','STM (RMSE)','FWI (RMSE)','M (RMSE)'])\n",
    "#results_df = results_df.append(rmse_df)\n",
    "results_df = pd.concat([results_df, rmse_df])\n",
    "\n",
    "del rmse_score, train_set, rmse_df     # Delete the variables you do not want to be picked up accidentally elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f083d6-7791-48f8-b64c-668995df2ecf",
   "metadata": {},
   "source": [
    "# Multiple Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a616027c-080d-41c3-a3ab-3f8288feeb95",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MULTIPLE REGRESSION\n",
      "******************************\n",
      "Train/Test running for 10 iterations.\n",
      "STFWI\n",
      "==========\n",
      "RMSE: 43.53604830037587\n",
      "STM\n",
      "==========\n",
      "RMSE: 43.40038262035092\n",
      "FWI\n",
      "==========\n",
      "RMSE: 43.39933286728688\n",
      "M\n",
      "==========\n",
      "RMSE: 43.38933684545374\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "print(\"MULTIPLE REGRESSION\")\n",
    "print(\"*\"*30)\n",
    "\n",
    "# Get the list of training / validating datasets\n",
    "train_set = { \"STFWI\" : MR_STFWI_df, \"STM\" : MR_STM_df, \"FWI\" : MR_FWI_df, \"M\" : MR_M_df}\n",
    "\n",
    "print(f\"Train/Test running for {train_test_iterations} iterations.\")\n",
    "\n",
    "rmse_score = []\n",
    "\n",
    "for key in train_set:\n",
    "    print(key)\n",
    "    print(\"=\"*10)\n",
    "\n",
    "    # Run 10 train / test splits and take the average RMSE for each dataset\n",
    "    results = []\n",
    "    for run in range(train_test_iterations):    \n",
    "        # Split the dataset for train/test\n",
    "        X_train, X_test, y_train, y_test = train_test_split( train_set[key], y_xformed, test_size=0.10, random_state=global_random_state)\n",
    "\n",
    "        # Set hyperparameters according to research paper.\n",
    "        # Use Least squares method.  Nothing to do. From scikit documentation: \n",
    "        # From the implementation point of view, this is just plain Ordinary Least Squares (scipy.linalg.lstsq)\"\n",
    "        model = LinearRegression()\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        rmse = calc_rmse( y_pred, y_test )\n",
    "        results.append(rmse)\n",
    "    \n",
    "    avg = sum(results) / len(results)\n",
    "    rmse_score.append(round(avg,1))\n",
    "    # print(results)\n",
    "    print(f\"RMSE: {avg}\")\n",
    "\n",
    "\n",
    "rmse_df = pd.DataFrame([['MR', rmse_score[0], rmse_score[1], rmse_score[2], rmse_score[3]]], columns=['Model','STFWI (RMSE)','STM (RMSE)','FWI (RMSE)','M (RMSE)'])\n",
    "results_df = pd.concat([results_df, rmse_df])\n",
    "#results_df = results_df.append(rmse_df)\n",
    "\n",
    "del rmse_score, train_set, rmse_df     # Delete the variables you do not want to be picked up accidentally elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8805a62-bb02-41be-82da-a9e41f0e509d",
   "metadata": {},
   "source": [
    "# SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "73ce76ea-e7c1-46e7-aae7-4aa984c48423",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVM\n",
      "******************************\n",
      "Train/Test running for 10 iterations.\n",
      "10\n",
      "==========\n",
      "RMSE: 43.8059800161267\n",
      "10\n",
      "==========\n",
      "RMSE: 43.735354570974934\n",
      "10\n",
      "==========\n",
      "RMSE: 43.79721785353759\n",
      "10\n",
      "==========\n",
      "RMSE: 43.84035512327204\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "print(\"SVM\")\n",
    "print(\"*\"*30)\n",
    "\n",
    "# Get the list of training / validating datasets\n",
    "train_set = { \"STFWI\" : SVM_STFWI_df, \"STM\" : SVM_STM_df, \"FWI\" : SVM_FWI_df, \"M\" : SVM_M_df}\n",
    "# The hyperparameters to use for each dataset\n",
    "gamma = { \"STFWI\" : 2.0e-5 , \"STM\" : 2.0e-3, \"FWI\" : 2.0e-3, \"M\" : 2.0e-2}\n",
    "\n",
    "print(f\"Train/Test running for {train_test_iterations} iterations.\")\n",
    "\n",
    "rmse_score = []\n",
    "\n",
    "for key in train_set:\n",
    "    print(train_test_iterations)\n",
    "    print(\"=\"*10)\n",
    "\n",
    "    # Run 10 train / test splits and take the average RMSE for each dataset\n",
    "    results = []\n",
    "    for run in range(train_test_iterations):        \n",
    "        # Split the dataset for train/test\n",
    "        X_train, X_test, y_train, y_test = train_test_split( train_set[key], y_xformed, test_size=0.10, random_state=global_random_state)\n",
    "\n",
    "        # Set hyperparameters according to research paper.\n",
    "        model = SVR(gamma=gamma[key], C=3, epsilon=0.1)\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "\n",
    "        rmse = calc_rmse( y_pred, y_test )\n",
    "        results.append(rmse)\n",
    "    \n",
    "    avg = sum(results) / len(results)\n",
    "    rmse_score.append(round(avg,1))\n",
    "    # print(results)\n",
    "    print(f\"RMSE: {avg}\")\n",
    "\n",
    "rmse_df = pd.DataFrame([['SVM', rmse_score[0], rmse_score[1], rmse_score[2], rmse_score[3]]], columns=['Model','STFWI (RMSE)','STM (RMSE)','FWI (RMSE)','M (RMSE)'])\n",
    "results_df = pd.concat([results_df, rmse_df])\n",
    "#results_df = results_df.append(rmse_df)\n",
    "\n",
    "del rmse_score, train_set, rmse_df     # Delete the variables you do not want to be picked up accidentally elsewhere."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30fb0501-50d3-497d-ba09-dd9f81afc903",
   "metadata": {},
   "source": [
    "# Display Final Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "51495b8d-f1d8-4d77-be11-24633b905881",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>STFWI (RMSE)</th>\n",
       "      <th>STM (RMSE)</th>\n",
       "      <th>FWI (RMSE)</th>\n",
       "      <th>M (RMSE)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive</td>\n",
       "      <td>63.594226</td>\n",
       "      <td>63.594226</td>\n",
       "      <td>63.594226</td>\n",
       "      <td>63.594226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>33.4</td>\n",
       "      <td>44.7</td>\n",
       "      <td>33.1</td>\n",
       "      <td>56.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>32.7</td>\n",
       "      <td>32.4</td>\n",
       "      <td>32.7</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MR</td>\n",
       "      <td>43.5</td>\n",
       "      <td>43.4</td>\n",
       "      <td>43.4</td>\n",
       "      <td>43.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>43.8</td>\n",
       "      <td>43.7</td>\n",
       "      <td>43.8</td>\n",
       "      <td>43.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Model STFWI (RMSE) STM (RMSE) FWI (RMSE)   M (RMSE)\n",
       "0  Naive    63.594226  63.594226  63.594226  63.594226\n",
       "0     DT         33.4       44.7       33.1       56.1\n",
       "0     RF         32.7       32.4       32.7       32.4\n",
       "0     MR         43.5       43.4       43.4       43.4\n",
       "0    SVM         43.8       43.7       43.8       43.8"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.round(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4a360c-0beb-4675-9fb0-6784a34fde36",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "Design and develop your own ML solution for this problem. The proposed solution should be different from all approaches mentioned in the provided article. This does not mean that you must have to choose a new ML algorithm. You can develop a novel solution by changing the feature selection approach or parameter optimisations process of used ML methods or using different ML methods or adding regularization or different combinations of them. This means, the proposed system should be substantially different from the methods presented in the article but not limited to only change of ML methods. Compare the RMSE result with reported methods in the article. Write in your report summarising your solution design and outcomes. The report should include:\n",
    "\n",
    "1. Motivation behind the proposed solution.\n",
    "2. How the proposed solution is different from existing ones.\n",
    "3. Detail description of the model including all parameters so that any reader can implement your model.\n",
    "4. Description of experimental protocol.\n",
    "5. Evaluation metrics. \n",
    "6. Present results using tables and graphs. \n",
    "7. Compare and discuss results with respect to existing literatures.\n",
    "8. Appropriate references (IEEE numbered).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cabf6fbf-c288-4f85-a927-7be92adaadfd",
   "metadata": {},
   "source": [
    "## Prepare the Neural Networkk Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bcb850e5-cd7e-4727-8856-896ecd2d7a3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_STFWI_df = STFWI_ohe_encoded_df\n",
    "NN_STM_df = STM_ohe_encoded_df\n",
    "NN_FWI_df = FWI_ohe_encoded_df\n",
    "NN_M_df = M_ohe_encoded_df\n",
    "\n",
    "NN_STFWI_df = standardise_dataset(\"NN_STFWI_df\", NN_STFWI_df, STFWI_ohe_encoded_cols)\n",
    "NN_STM_df = standardise_dataset(\"NN_STM_df\", NN_STM_df, STM_ohe_encoded_cols)\n",
    "NN_FWI_df = standardise_dataset(\"NN_FWI_df\", NN_FWI_df, FWI_ohe_encoded_cols)\n",
    "NN_M_df = standardise_dataset(\"NN_M_df\", NN_M_df, M_ohe_encoded_cols)\n",
    "\n",
    "# Save the dataset to a file for manual exploration and verifiaction of feature engineering.\n",
    "save_dataset( \"NN_STFWI_df\", NN_STFWI_df )\n",
    "save_dataset( \"NN_STM_df\", NN_STM_df )\n",
    "save_dataset( \"NN_FWI_df\", NN_FWI_df )\n",
    "save_dataset( \"NN_M_df\", NN_M_df )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40d98ef9-c4f4-4838-b7f9-4d5b3aace1f4",
   "metadata": {},
   "source": [
    "## Neural Network Regressor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b446da09-9532-47b4-bbcb-989eb9c6a2bf",
   "metadata": {},
   "source": [
    "# Find the best Neural Network Model\n",
    "\n",
    "Perform a grid search to find the best hyperparameters. We will start with the parameters described in the research paper and add additional hyperparameters.\n",
    "\n",
    "The method will use an inner/outer train/test approach. The dataset is divided using 10-fold, and each fold is split into 3 for conducting the grid search.\n",
    "\n",
    "The main hyperparameter to explor is the number of hidden dimensions/layer size. A different gradient descent approach will be explored a,d the strength of the regularisation. Two solvers were selected out of a possible three. adam was not explored because this is recommended for large datasets.\n",
    "\n",
    "## NOTE\n",
    "This code takes approximately two hours to run so it has been tagged not to run by default. To run this block of code change the block type from Raw to Code. Refer to the assignment-submission document for a copy of the grid search output."
   ]
  },
  {
   "cell_type": "raw",
   "id": "62d990a8-2318-4a43-b044-4d7cd92ac5c1",
   "metadata": {},
   "source": [
    "# manual nested cross-validation for random forest on a classification dataset\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "\n",
    "# Get the list of training / validating datasets\n",
    "train_set = { \"STFWI\" : NN_STFWI_df, \"STM\" : NN_STM_df, \"FWI\" : NN_FWI_df, \"M\" : NN_M_df}\n",
    "\n",
    "# Iterate through the four datasets and identify the best hyperparameter combination for each\n",
    "for key in train_set:\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Searching for hyperparameters for dataset: {key}\")\n",
    "    print(\"=\"*40)\n",
    "    \n",
    "    # Need to convert the dataframes to arrays so the KFold can work.\n",
    "    X = np.array(train_set[key])\n",
    "    y = np.array(y_xformed)\n",
    "\n",
    "    # configure the cross-validation procedure\n",
    "    cv_outer = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    \n",
    "    # enumerate splits\n",
    "    outer_results = list()\n",
    "    for train_ix, test_ix in cv_outer.split(X):\n",
    "        print(\">\", end='')\n",
    "        # split data\n",
    "        X_train, X_test = X[train_ix, :], X[test_ix, :]\n",
    "        y_train, y_test = y[train_ix], y[test_ix]\n",
    "        # configure the cross-validation procedure\n",
    "        cv_inner = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "        # define the model\n",
    "        # model = RandomForestClassifier(random_state=1)\n",
    "        model = MLPRegressor(random_state=1, max_iter=20000, hidden_layer_sizes=(2), activation='tanh', solver='lbfgs')\n",
    "\n",
    "        # define search space\n",
    "        space = dict()\n",
    "        space['hidden_layer_sizes'] = [(2), (4), (6), (10), (20), (50), (100)]\n",
    "        space['solver'] = ['lbfgs', 'sgd']\n",
    "        space['alpha'] = [0.0001, 0.05]\n",
    "        space['learning_rate'] = ['constant', 'adaptive']\n",
    "        # define search\n",
    "        search = GridSearchCV(model, space, scoring='neg_mean_squared_error', cv=cv_inner, refit=True)\n",
    "        # execute search\n",
    "        result = search.fit(X_train, y_train)\n",
    "        # get the best performing model fit on the whole training set\n",
    "        best_model = result.best_estimator_\n",
    "        #print(result.best_params_)\n",
    "\n",
    "        # evaluate model on the hold out dataset\n",
    "        y_pred = best_model.predict(X_test)\n",
    "        rmse = calc_rmse( y_pred, y_test )\n",
    "\n",
    "        # store the result\n",
    "        outer_results.append(rmse)\n",
    "\n",
    "        # report progress\n",
    "        print('rmse=%.3f, est=%.3f, cfg=%s' % (rmse, result.best_score_, result.best_params_))\n",
    "    # summarize the estimated performance of the model\n",
    "    print('RMSE: %.3f RMSE SD: (%.3f)' % (mean(outer_results), std(outer_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f801fb3d-b323-4b38-8146-4f65e8313500",
   "metadata": {},
   "source": [
    "## Train the Neural Network\n",
    "\n",
    "Using th hyperparameters identified in the grid search above, train the model and measure the performance. Append the results to the main results table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dfe5b48e-ba21-4c16-970d-570336fe43e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEURAL NETWORK\n",
      "******************************\n",
      "==========\n",
      "STFWI\n",
      "67.09553097750889\n",
      "67.09553097750889\n",
      "67.09553097750889\n",
      "67.09553097750889\n",
      "67.09553097750889\n",
      "67.09553097750889\n",
      "67.09553097750889\n",
      "67.09553097750889\n",
      "67.09553097750889\n",
      "67.09553097750889\n",
      "RMSE: 32.4667033491962\n",
      "==========\n",
      "STM\n",
      "67.05048692008042\n",
      "67.05048692008042\n",
      "67.05048692008042\n",
      "67.05048692008042\n",
      "67.05048692008042\n",
      "67.05048692008042\n",
      "67.05048692008042\n",
      "67.05048692008042\n",
      "67.05048692008042\n",
      "67.05048692008042\n",
      "RMSE: 32.438487157969625\n",
      "==========\n",
      "FWI\n",
      "67.13285314478401\n",
      "67.13285314478401\n",
      "67.13285314478401\n",
      "67.13285314478401\n",
      "67.13285314478401\n",
      "67.13285314478401\n",
      "67.13285314478401\n",
      "67.13285314478401\n",
      "67.13285314478401\n",
      "67.13285314478401\n",
      "RMSE: 32.38758030377324\n",
      "==========\n",
      "M\n",
      "67.09459880158919\n",
      "67.09459880158919\n",
      "67.09459880158919\n",
      "67.09459880158919\n",
      "67.09459880158919\n",
      "67.09459880158919\n",
      "67.09459880158919\n",
      "67.09459880158919\n",
      "67.09459880158919\n",
      "67.09459880158919\n",
      "RMSE: 32.542732657400045\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPRegressor\n",
    "\n",
    "print(\"NEURAL NETWORK\")\n",
    "print(\"*\"*30)\n",
    "\n",
    "# Get the list of training / validating datasets\n",
    "train_set = { \"STFWI\" : NN_STFWI_df, \"STM\" : NN_STM_df, \"FWI\" : NN_FWI_df, \"M\" : NN_M_df}\n",
    "\n",
    "# The hyperparameters to use for each dataset. These are identified from the grid search above.\n",
    "H = { \"STFWI\" : 2 , \"STM\" : 2, \"FWI\" : 6, \"M\" : 6}\n",
    "alpha = { \"STFWI\" : 0.05 , \"STM\" : 0.05, \"FWI\" : 0.05, \"M\" : 0.05}\n",
    "solver = { \"STFWI\" : 'sgd' , \"STM\" : 'sgd', \"FWI\" : 'sgd', \"M\" : 'sgd'}\n",
    "learning_rate = { \"STFWI\" : 'constant' , \"STM\" : 'constant', \"FWI\" : 'constant', \"M\" : 'adaptive'}\n",
    "\n",
    "rmse_score = []\n",
    "\n",
    "# Iterate over each dataset, fit the mode and evaluate the performance with RMSE\n",
    "for key in train_set:\n",
    "    print(\"=\"*10)\n",
    "    print(key)\n",
    "\n",
    "    # Run 10 train / test splits and take the average RMSE for each dataset\n",
    "    results = []\n",
    "    for run in range(10):\n",
    "        # Split the dataset for train/test\n",
    "        X_train, X_test, y_train, y_test = train_test_split( train_set[key], y_xformed, test_size=0.10, random_state=8)\n",
    "\n",
    "        # Set hyperparameters according to the research paper\n",
    "        model = MLPRegressor(random_state=1, max_iter=20000, activation='tanh', hidden_layer_sizes=(H[key]), solver=solver[key], alpha=alpha[key], learning_rate=learning_rate[key])\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)            \n",
    "        rmse = calc_rmse( y_pred, y_test )\n",
    "        results.append(rmse)\n",
    "\n",
    "        # Calculate the rmse on the training dataset. If rmse(train) < rmse(test) then the model is overfitten.\n",
    "        train_pred = model.predict(X_train)\n",
    "        train_rmse = calc_rmse( train_pred, y_train)\n",
    "        print(train_rmse)\n",
    "\n",
    "    avg = sum(results) / len(results)\n",
    "    rmse_score.append(round(avg,1))\n",
    "    # print(results)\n",
    "    print(f\"RMSE: {avg}\")\n",
    "\n",
    "rmse_df = pd.DataFrame([['Q2: NN', rmse_score[0], rmse_score[1], rmse_score[2], rmse_score[3]]], columns=['Model','STFWI (RMSE)','STM (RMSE)','FWI (RMSE)','M (RMSE)'])\n",
    "results_df = pd.concat([results_df, rmse_df])\n",
    "#results_df = results_df.append(rmse_df)\n",
    "    \n",
    "del rmse_score, train_set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb6c693-c172-48ea-ac67-c877b20385ac",
   "metadata": {},
   "source": [
    "## Update Results Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "181ad536-e051-4879-a8fe-e342b318cae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>STFWI (RMSE)</th>\n",
       "      <th>STM (RMSE)</th>\n",
       "      <th>FWI (RMSE)</th>\n",
       "      <th>M (RMSE)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Naive</td>\n",
       "      <td>63.594226</td>\n",
       "      <td>63.594226</td>\n",
       "      <td>63.594226</td>\n",
       "      <td>63.594226</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DT</td>\n",
       "      <td>33.4</td>\n",
       "      <td>44.7</td>\n",
       "      <td>33.1</td>\n",
       "      <td>56.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RF</td>\n",
       "      <td>32.7</td>\n",
       "      <td>32.4</td>\n",
       "      <td>32.7</td>\n",
       "      <td>32.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>MR</td>\n",
       "      <td>43.5</td>\n",
       "      <td>43.4</td>\n",
       "      <td>43.4</td>\n",
       "      <td>43.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVM</td>\n",
       "      <td>43.8</td>\n",
       "      <td>43.7</td>\n",
       "      <td>43.8</td>\n",
       "      <td>43.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Q2: NN</td>\n",
       "      <td>32.5</td>\n",
       "      <td>32.4</td>\n",
       "      <td>32.4</td>\n",
       "      <td>32.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Model STFWI (RMSE) STM (RMSE) FWI (RMSE)   M (RMSE)\n",
       "0   Naive    63.594226  63.594226  63.594226  63.594226\n",
       "0      DT         33.4       44.7       33.1       56.1\n",
       "0      RF         32.7       32.4       32.7       32.4\n",
       "0      MR         43.5       43.4       43.4       43.4\n",
       "0     SVM         43.8       43.7       43.8       43.8\n",
       "0  Q2: NN         32.5       32.4       32.4       32.5"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.round(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d41aa3f6-6fd3-4c87-95ed-ffb874046424",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
